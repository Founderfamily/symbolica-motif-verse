// Edge Function ultra-simple pour tester la connectivit√© IA
import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.7.1';

console.log('üöÄ [AI-INVESTIGATION-V2] Function d√©marr√©e - premi√®re ligne ex√©cut√©e');

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

serve(async (req) => {
  console.log('üì• [AI-INVESTIGATION-V2] Requ√™te re√ßue:', req.method);
  
  // Handle CORS preflight requests
  if (req.method === 'OPTIONS') {
    console.log('‚úÖ [AI-INVESTIGATION-V2] CORS preflight - r√©ponse envoy√©e');
    return new Response(null, { headers: corsHeaders });
  }

  try {
    console.log('üîç [AI-INVESTIGATION-V2] Parsing body...');
    
    // Protection contre les timeouts et erreurs de parsing
    let body;
    try {
      const bodyText = await req.text();
      console.log('üìÑ [AI-INVESTIGATION-V2] Body text length:', bodyText.length);
      body = JSON.parse(bodyText);
      console.log('üìù [AI-INVESTIGATION-V2] Body pars√© avec succ√®s. Action:', body?.action);
    } catch (parseError) {
      console.error('‚ùå [AI-INVESTIGATION-V2] Erreur parsing body:', parseError);
      return new Response(JSON.stringify({ 
        status: 'error', 
        message: 'Erreur de format de requ√™te',
        error: parseError.message
      }), {
        status: 400,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    // Test de base - r√©pondre "pong"
    if (body.action === 'ping') {
      console.log('üèì [AI-INVESTIGATION-V2] Ping re√ßu - r√©ponse pong');
      return new Response(JSON.stringify({ 
        status: 'success', 
        message: 'pong',
        timestamp: new Date().toISOString(),
        receivedData: body
      }), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    // Test avec OpenAI si cl√© disponible
    if (body.action === 'test_openai') {
      console.log('ü§ñ [AI-INVESTIGATION-V2] Test OpenAI demand√©');
      
      const openaiKey = Deno.env.get('OPENAI_API_KEY');
      console.log('üîë [AI-INVESTIGATION-V2] OpenAI key disponible:', !!openaiKey);
      
      if (!openaiKey) {
        console.log('‚ùå [AI-INVESTIGATION-V2] Pas de cl√© OpenAI');
        return new Response(JSON.stringify({ 
          status: 'error', 
          message: 'Cl√© OpenAI manquante',
          openaiKeyAvailable: false
        }), {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });
      }

      console.log('üîó [AI-INVESTIGATION-V2] Appel OpenAI...');
      const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${openaiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'gpt-4o-mini',
          messages: [
            { role: 'system', content: 'Tu es un assistant de test. R√©ponds simplement "Test OpenAI r√©ussi".' },
            { role: 'user', content: 'Test de connectivit√©' }
          ],
          max_tokens: 50
        }),
      });

      console.log('üìä [AI-INVESTIGATION-V2] OpenAI status:', openaiResponse.status);
      
      if (!openaiResponse.ok) {
        const errorText = await openaiResponse.text();
        console.log('‚ùå [AI-INVESTIGATION-V2] Erreur OpenAI:', errorText);
        return new Response(JSON.stringify({ 
          status: 'error', 
          message: 'Erreur OpenAI',
          error: errorText,
          openaiStatus: openaiResponse.status
        }), {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });
      }

      const openaiData = await openaiResponse.json();
      console.log('‚úÖ [AI-INVESTIGATION-V2] OpenAI r√©ponse re√ßue');
      
      return new Response(JSON.stringify({ 
        status: 'success', 
        message: 'OpenAI connect√© avec succ√®s',
        aiResponse: openaiData.choices[0].message.content,
        timestamp: new Date().toISOString()
      }), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    // === NOUVELLES FONCTIONNALIT√âS IA ===

    // Investigation compl√®te d'une qu√™te
    if (body.action === 'full_investigation') {
      console.log('üîç [AI-INVESTIGATION-V2] Investigation compl√®te demand√©e');
      
      const openaiKey = Deno.env.get('OPENAI_API_KEY');
      const supabaseUrl = Deno.env.get('SUPABASE_URL');
      const supabaseKey = Deno.env.get('SUPABASE_ANON_KEY');
      
      if (!openaiKey) {
        return new Response(JSON.stringify({ 
          status: 'error', 
          message: 'Cl√© OpenAI manquante' 
        }), {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });
      }

      // Cr√©er client Supabase
      const supabase = createClient(supabaseUrl!, supabaseKey!);
      
      const questData = body.questData || {};
      const questId = body.questId;
      const userId = body.userId || 'anonymous';
      
      // V√©rifier l'authentification pour la sauvegarde - plus strict
      const canSave = userId !== 'anonymous' && userId && userId.length > 30; // UUID valide
      
      console.log('üìù [AI-INVESTIGATION-V2] Donn√©es qu√™te re√ßues:', Object.keys(questData));

      // R√©cup√©rer les preuves existantes pour cette qu√™te
      console.log('üîç [AI-INVESTIGATION-V2] R√©cup√©ration des preuves existantes...');
      const { data: existingEvidence, error: evidenceError } = await supabase
        .from('quest_evidence')
        .select('*')
        .eq('quest_id', questId);

      if (evidenceError) {
        console.error('‚ùå [AI-INVESTIGATION-V2] Erreur r√©cup√©ration preuves:', evidenceError);
      }

      const evidenceContext = existingEvidence && existingEvidence.length > 0 
        ? `\n\nPREUVES EXISTANTES SOUMISES PAR LA COMMUNAUT√â :\n${existingEvidence.map((evidence: any, index: number) => 
            `${index + 1}. ${evidence.title} (${evidence.evidence_type})
               - Description: ${evidence.description || 'Non sp√©cifi√©e'}
               - Localisation: ${evidence.location_name || 'Non sp√©cifi√©e'}
               - Statut de validation: ${evidence.validation_status}
               - Score: ${evidence.validation_score}`
          ).join('\n')}`
        : '\n\nAucune preuve n\'a encore √©t√© soumise par la communaut√© pour cette qu√™te.';

      const investigationPrompt = `Tu es un expert en recherche historique et symbolique. Analyse cette qu√™te de tr√©sor et fournis une investigation compl√®te.

Donn√©es de la qu√™te:
- Titre: ${questData.title || 'Non sp√©cifi√©'}
- Type: ${questData.quest_type || 'Non sp√©cifi√©'}
- Difficult√©: ${questData.difficulty_level || 'Non sp√©cifi√©'}
- Description: ${questData.description || 'Non sp√©cifi√©'}
- Contexte historique: ${questData.story_background || 'Non sp√©cifi√©'}

Indices de la qu√™te :
${questData.clues?.map((clue: any, index: number) => 
  `${index + 1}. ${clue.title}: ${clue.description} (Indice: ${clue.hint})`
).join('\n')}

${evidenceContext}

Instructions:
1. Analyse les √©l√©ments historiques et symboliques
2. Identifie les connexions potentielles entre les indices
3. Int√®gre et analyse les preuves existantes soumises par la communaut√©
4. Sugg√®re des pistes de recherche suppl√©mentaires bas√©es sur les √©l√©ments historiques et les preuves
5. Propose des th√©ories sur la localisation
6. Recommande des sources √† consulter
7. Identifie les types de preuves suppl√©mentaires √† rechercher

R√©ponds en fran√ßais avec une analyse structur√©e et d√©taill√©e.`;

      try {
        const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${openaiKey}`,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            model: 'gpt-4o-mini',
            messages: [
              { role: 'system', content: 'Tu es un expert en investigation historique et symbolique sp√©cialis√© dans la recherche de tr√©sors.' },
              { role: 'user', content: investigationPrompt }
            ],
            max_tokens: 1500,
            temperature: 0.7
          }),
        });

        if (!openaiResponse.ok) {
          throw new Error(`OpenAI API error: ${openaiResponse.status}`);
        }

        const openaiData = await openaiResponse.json();
        const investigationResult = openaiData.choices[0].message.content;
        console.log('‚úÖ [AI-INVESTIGATION-V2] Investigation compl√®te g√©n√©r√©e');
        
        // Sauvegarder l'investigation dans la base de donn√©es si l'utilisateur est authentifi√©
        let savedInvestigation = null;
        let saveError = null;
        
        if (canSave) {
          console.log('üíæ [AI-INVESTIGATION-V2] Sauvegarde en base...');
          const { data: saved, error: error } = await supabase
            .from('ai_investigations')
            .insert({
              quest_id: questId,
              investigation_type: 'full_investigation',
              result_content: {
                investigation: investigationResult,
                quest_data: questData,
                evidence_count: existingEvidence?.length || 0
              },
              evidence_used: existingEvidence || [],
              created_by: userId
            })
            .select()
            .single();

          savedInvestigation = saved;
          saveError = error;

          if (saveError) {
            console.error('‚ùå [AI-INVESTIGATION-V2] Erreur sauvegarde:', saveError);
          } else {
            console.log('‚úÖ [AI-INVESTIGATION-V2] Investigation sauvegard√©e avec l\'ID:', savedInvestigation.id);
          }
        } else {
          console.log('‚ö†Ô∏è [AI-INVESTIGATION-V2] Pas de sauvegarde - utilisateur non authentifi√©');
        }
        
        // R√©ponse ultra-robuste avec fallbacks multiples
        const responseData = {
          status: 'success', 
          message: canSave ? 'Investigation compl√®te g√©n√©r√©e et sauvegard√©e' : 'Investigation g√©n√©r√©e (non sauvegard√©e - connexion requise)',
          investigation: investigationResult,
          investigation_id: savedInvestigation?.id,
          saved: !!savedInvestigation,
          save_error: saveError?.message,
          auth_required: !canSave,
          timestamp: new Date().toISOString(),
          // Fallbacks pour compatibilit√©
          content: investigationResult, // Alias pour investigation
          result: investigationResult,  // Autre alias
          success: true,
          data: investigationResult
        };

        console.log('üéØ [AI-INVESTIGATION-V2] Envoi r√©ponse robuste. Cl√©s:', Object.keys(responseData));

        return new Response(JSON.stringify(responseData), {
          status: 200,
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });

      } catch (error) {
        console.error('‚ùå [AI-INVESTIGATION-V2] Erreur investigation:', error);
        return new Response(JSON.stringify({ 
          status: 'error', 
          message: 'Erreur lors de l\'investigation',
          error: error.message
        }), {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });
      }
    }

    // Recherche de sources historiques
    if (body.action === 'search_historical_sources') {
      console.log('üìö [AI-INVESTIGATION-V2] Recherche sources historiques');
      
      const openaiKey = Deno.env.get('OPENAI_API_KEY');
      if (!openaiKey) {
        return new Response(JSON.stringify({ 
          status: 'error', 
          message: 'Cl√© OpenAI manquante' 
        }), {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });
      }

      const questData = body.questData || {};
      const searchPrompt = `Recherche et identifie des sources historiques pertinentes pour cette qu√™te:

Contexte de la qu√™te:
- Titre: ${questData.title || 'Non sp√©cifi√©'}
- Culture/√âpoque: ${questData.culture || questData.period || 'Non sp√©cifi√©'}
- Localisation: ${questData.location || 'Non sp√©cifi√©'}
- Symboles associ√©s: ${JSON.stringify(questData.target_symbols || [])}

Trouve et sugg√®re:
1. Archives historiques √† consulter
2. Manuscrits anciens pertinents
3. Cartes historiques de la r√©gion
4. Chroniques et t√©moignages d'√©poque
5. Sources arch√©ologiques
6. Bases de donn√©es sp√©cialis√©es

Pour chaque source, indique: nom, p√©riode, localisation, pertinence et accessibilit√©.`;

      try {
        const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${openaiKey}`,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            model: 'gpt-4o-mini',
            messages: [
              { role: 'system', content: 'Tu es un archiviste expert et historien sp√©cialis√© dans la localisation de sources historiques.' },
              { role: 'user', content: searchPrompt }
            ],
            max_tokens: 1200,
            temperature: 0.6
          }),
        });

        if (!openaiResponse.ok) {
          throw new Error(`OpenAI API error: ${openaiResponse.status}`);
        }

        const openaiData = await openaiResponse.json();
        console.log('‚úÖ [AI-INVESTIGATION-V2] Sources historiques trouv√©es');
        
        return new Response(JSON.stringify({ 
          status: 'success', 
          message: 'Sources historiques identifi√©es',
          sources: openaiData.choices[0].message.content,
          timestamp: new Date().toISOString()
        }), {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });

      } catch (error) {
        console.error('‚ùå [AI-INVESTIGATION-V2] Erreur recherche sources:', error);
        return new Response(JSON.stringify({ 
          status: 'error', 
          message: 'Erreur lors de la recherche de sources',
          error: error.message
        }), {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });
      }
    }

    // G√©n√©ration de th√©ories
    if (body.action === 'generate_theories') {
      console.log('üí° [AI-INVESTIGATION-V2] G√©n√©ration de th√©ories');
      
      const openaiKey = Deno.env.get('OPENAI_API_KEY');
      if (!openaiKey) {
        return new Response(JSON.stringify({ 
          status: 'error', 
          message: 'Cl√© OpenAI manquante' 
        }), {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });
      }

      const questData = body.questData || {};
      const evidenceData = body.evidenceData || [];
      
      const theoriesPrompt = `G√©n√®re des th√©ories d'investigation pour cette qu√™te en te basant sur les donn√©es disponibles:

Qu√™te: ${questData.title || 'Non sp√©cifi√©'}
Type: ${questData.quest_type || 'Non sp√©cifi√©'}
Context: ${questData.description || 'Non sp√©cifi√©'}

Indices disponibles: ${JSON.stringify(questData.clues || [])}
Preuves soumises: ${evidenceData.length} √©l√©ments

G√©n√®re 3-5 th√©ories diff√©rentes avec:
1. Nom de la th√©orie
2. Description d√©taill√©e
3. √âl√©ments supportant cette th√©orie
4. Pr√©dictions v√©rifiables
5. Niveau de confiance (1-10)
6. Prochaines √©tapes sugg√©r√©es

Sois cr√©atif mais reste bas√© sur les faits disponibles.`;

      try {
        const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${openaiKey}`,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            model: 'gpt-4o-mini',
            messages: [
              { role: 'system', content: 'Tu es un th√©oricien expert en chasse au tr√©sor, capable de formuler des hypoth√®ses cr√©atives mais fond√©es.' },
              { role: 'user', content: theoriesPrompt }
            ],
            max_tokens: 1400,
            temperature: 0.8
          }),
        });

        if (!openaiResponse.ok) {
          throw new Error(`OpenAI API error: ${openaiResponse.status}`);
        }

        const openaiData = await openaiResponse.json();
        console.log('‚úÖ [AI-INVESTIGATION-V2] Th√©ories g√©n√©r√©es');
        
        return new Response(JSON.stringify({ 
          status: 'success', 
          message: 'Th√©ories d\'investigation g√©n√©r√©es',
          theories: openaiData.choices[0].message.content,
          timestamp: new Date().toISOString()
        }), {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });

      } catch (error) {
        console.error('‚ùå [AI-INVESTIGATION-V2] Erreur g√©n√©ration th√©ories:', error);
        return new Response(JSON.stringify({ 
          status: 'error', 
          message: 'Erreur lors de la g√©n√©ration de th√©ories',
          error: error.message
        }), {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });
      }
    }

    // Analyse des connexions
    if (body.action === 'analyze_connections') {
      console.log('üîó [AI-INVESTIGATION-V2] Analyse des connexions');
      
      const openaiKey = Deno.env.get('OPENAI_API_KEY');
      if (!openaiKey) {
        return new Response(JSON.stringify({ 
          status: 'error', 
          message: 'Cl√© OpenAI manquante' 
        }), {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });
      }

      const questData = body.questData || {};
      const evidenceData = body.evidenceData || [];
      const theoriesData = body.theoriesData || [];
      
      const connectionsPrompt = `Analyse les connexions entre tous les √©l√©ments de cette investigation:

QU√äTE: ${questData.title || 'Non sp√©cifi√©'}
INDICES: ${JSON.stringify(questData.clues || [])}
PREUVES: ${evidenceData.length} √©l√©ments soumis
TH√âORIES: ${theoriesData.length} th√©ories propos√©es

Identifie et analyse:
1. Connexions entre les indices officiels
2. Relations entre les preuves soumises
3. Support des preuves pour chaque th√©orie
4. Patterns g√©ographiques ou temporels
5. √âl√©ments manquants critiques
6. Contradictions √† r√©soudre
7. Convergences significatives

Pr√©sente ton analyse sous forme de carte des connexions avec forces de liaison.`;

      try {
        const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${openaiKey}`,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            model: 'gpt-4o-mini',
            messages: [
              { role: 'system', content: 'Tu es un analyste expert en investigation, sp√©cialis√© dans l\'identification de patterns et connexions.' },
              { role: 'user', content: connectionsPrompt }
            ],
            max_tokens: 1300,
            temperature: 0.7
          }),
        });

        if (!openaiResponse.ok) {
          throw new Error(`OpenAI API error: ${openaiResponse.status}`);
        }

        const openaiData = await openaiResponse.json();
        console.log('‚úÖ [AI-INVESTIGATION-V2] Analyse des connexions termin√©e');
        
        return new Response(JSON.stringify({ 
          status: 'success', 
          message: 'Analyse des connexions termin√©e',
          connections: openaiData.choices[0].message.content,
          timestamp: new Date().toISOString()
        }), {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });

      } catch (error) {
        console.error('‚ùå [AI-INVESTIGATION-V2] Erreur analyse connexions:', error);
        return new Response(JSON.stringify({ 
          status: 'error', 
          message: 'Erreur lors de l\'analyse des connexions',
          error: error.message
        }), {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });
      }
    }

    // Action par d√©faut
    console.log('‚ùì [AI-INVESTIGATION-V2] Action inconnue:', body.action);
    return new Response(JSON.stringify({ 
      status: 'error', 
      message: 'Action non reconnue',
      availableActions: ['ping', 'test_openai', 'full_investigation', 'search_historical_sources', 'generate_theories', 'analyze_connections'],
      receivedAction: body.action
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });

  } catch (error) {
    console.error('üí• [AI-INVESTIGATION-V2] Erreur:', error);
    return new Response(JSON.stringify({ 
      status: 'error', 
      message: error.message,
      stack: error.stack 
    }), {
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });
  }
});